# ğŸ“š RAG Chat UygulamasÄ±

OpenAI ve Pinecone kullanarak dokÃ¼manlar Ã¼zerinden soru-cevap yapabilen bir RAG (Retrieval Augmented Generation) uygulamasÄ±.

## ğŸŒŸ Ã–zellikler

- ğŸ“„ **Ã‡oklu DokÃ¼man DesteÄŸi**: PDF, TXT ve DOCX formatlarÄ±nda dokÃ¼man yÃ¼kleme
- ğŸ¤– **Premium Embedding**: OpenAI'Ä±n text-embedding-3-large modeli ile yÃ¼ksek kaliteli vektÃ¶rize etme
- â˜ï¸ **Cloud Depolama**: Pinecone vector database ile vektÃ¶rleri bulutta saklama
- ğŸ’¬ **Sohbet ArayÃ¼zÃ¼**: Streamlit tabanlÄ± kullanÄ±cÄ± dostu chat interface
- ğŸ§  **GeliÅŸmiÅŸ RAG Pipeline**: DokÃ¼manlarÄ±nÄ±zdan ilgili bilgileri bulup GPT-4o ile akÄ±llÄ± analiz
- ğŸ“Š **Ä°statistikler**: YÃ¼klenen dokÃ¼man ve vector sayÄ±sÄ± gÃ¶sterimi
- ğŸ¯ **AkÄ±llÄ± Filtreleme**: Similarity threshold ile kaliteli sonuÃ§lar
- ğŸ” **Kaynak ReferanslarÄ±**: Her cevap iÃ§in detaylÄ± kaynak bilgileri

## ğŸš€ Kurulum

### Gereksinimler

- Python 3.8 veya Ã¼zeri
- OpenAI API key
- Pinecone API key

### AdÄ±mlar

1. **Repoyu klonlayÄ±n veya dosyalarÄ± indirin**

2. **Virtual environment oluÅŸturun (opsiyonel ama Ã¶nerilir)**
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

3. **Gerekli paketleri yÃ¼kleyin**
```bash
pip install -r requirements.txt
```

4. **API anahtarlarÄ±nÄ±zÄ± ayarlayÄ±n**

Proje klasÃ¶rÃ¼nde `.env` dosyasÄ± oluÅŸturun ve aÅŸaÄŸÄ±daki bilgileri girin:

```env
# OpenAI API Key
OPENAI_API_KEY=sk-your-openai-api-key-here

# Pinecone API Key
PINECONE_API_KEY=your-pinecone-api-key-here

# Pinecone Index Name (istediÄŸiniz ismi verebilirsiniz)
PINECONE_INDEX_NAME=rag-documents
```

**API Key'leri Nereden AlÄ±nÄ±r?**

- **OpenAI API Key**: [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)
- **Pinecone API Key**: [https://app.pinecone.io/](https://app.pinecone.io/) (Ã¼cretsiz plan mevcut)

**Pinecone Index Name Nedir?**

Index adÄ±nÄ± siz belirlersiniz. Ã–rneÄŸin: `rag-documents`, `my-docs`, vb. 
Uygulama ilk Ã§alÄ±ÅŸtÄ±ÄŸÄ±nda bu isimde bir index yoksa otomatik olarak oluÅŸturulacaktÄ±r.

## ğŸ“– KullanÄ±m

1. **UygulamayÄ± baÅŸlatÄ±n**
```bash
streamlit run app.py
```

2. **TarayÄ±cÄ±nÄ±zda aÃ§Ä±lacak olan uygulamada:**
   - Sol menÃ¼den dokÃ¼manlarÄ±nÄ±zÄ± yÃ¼kleyin (PDF, TXT veya DOCX)
   - "DokÃ¼manlarÄ± Ä°ÅŸle ve Kaydet" butonuna tÄ±klayÄ±n
   - DokÃ¼manlarÄ±nÄ±z iÅŸlenip Pinecone'a kaydedilecek
   - ArtÄ±k chat alanÄ±ndan sorularÄ±nÄ±zÄ± sorabilirsiniz!

3. **Ã–rnek sorular:**
   - "Bu dokÃ¼manda ana konular nelerdir?"
   - "X hakkÄ±nda ne sÃ¶yleniyor?"
   - "Y ile ilgili detaylarÄ± Ã¶zetle"

## ğŸ—ï¸ Proje YapÄ±sÄ±

```
vectorize/
â”œâ”€â”€ app.py                    # Ana Streamlit uygulamasÄ±
â”œâ”€â”€ config.py                 # YapÄ±landÄ±rma ayarlarÄ±
â”œâ”€â”€ document_processor.py     # DokÃ¼man iÅŸleme modÃ¼lÃ¼
â”œâ”€â”€ vector_store.py          # Pinecone ve embedding yÃ¶netimi
â”œâ”€â”€ requirements.txt         # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ .env                     # API anahtarlarÄ± (oluÅŸturmanÄ±z gerekiyor)
â””â”€â”€ README.md               # Bu dosya
```

## âš™ï¸ YapÄ±landÄ±rma

`config.py` dosyasÄ±ndan aÅŸaÄŸÄ±daki ayarlarÄ± Ã¶zelleÅŸtirebilirsiniz:

- `EMBEDDING_MODEL`: KullanÄ±lan embedding modeli (varsayÄ±lan: text-embedding-3-large)
- `CHAT_MODEL`: Chat iÃ§in kullanÄ±lan model (varsayÄ±lan: gpt-4o)
- `EMBEDDING_DIMENSION`: Embedding boyutu (varsayÄ±lan: 3072)
- `CHUNK_SIZE`: DokÃ¼man chunk boyutu (varsayÄ±lan: 1200 karakter)
- `CHUNK_OVERLAP`: Chunk'lar arasÄ± Ã¶rtÃ¼ÅŸme (varsayÄ±lan: 200 karakter)
- `TOP_K`: Query'de dÃ¶ndÃ¼rÃ¼lecek chunk sayÄ±sÄ± (varsayÄ±lan: 8)
- `SIMILARITY_THRESHOLD`: Minimum benzerlik skoru (varsayÄ±lan: 0.25)
- `MAX_CONTEXT_LENGTH`: Maksimum context uzunluÄŸu (varsayÄ±lan: 8000 karakter)

### Model Alternatifleri

#### Chat Modelleri:
- `CHAT_MODEL = "gpt-4o"` - HÄ±zlÄ±, gÃ¼Ã§lÃ¼, gÃ¼venilir (Ã¶nerilen)
- `CHAT_MODEL = "gpt-4o-mini"` - Ekonomik seÃ§enek
- `CHAT_MODEL = "gpt-5"` - En yeni model (API eriÅŸimi gerekebilir)
- `CHAT_MODEL = "gpt-5-mini"` - Ekonomik GPT-5

#### Embedding Modelleri:
- `EMBEDDING_MODEL = "text-embedding-3-large"` - En kaliteli (3072 dimension)
- `EMBEDDING_MODEL = "text-embedding-3-small"` - Ekonomik (1536 dimension)

**Ã–NEMLÄ°:** Embedding modelini deÄŸiÅŸtirirseniz `EMBEDDING_DIMENSION` deÄŸerini de gÃ¼ncelleyin:
- text-embedding-3-large â†’ 3072
- text-embedding-3-small â†’ 1536

## ğŸ’¡ NasÄ±l Ã‡alÄ±ÅŸÄ±r?

1. **DokÃ¼man YÃ¼kleme**: KullanÄ±cÄ± PDF/TXT/DOCX dosyalarÄ±nÄ± yÃ¼kler
2. **Metin Ã‡Ä±karma**: DokÃ¼manlardan metin Ã§Ä±karÄ±lÄ±r
3. **Chunking**: Metin kÃ¼Ã§Ã¼k parÃ§alara (chunks) bÃ¶lÃ¼nÃ¼r
4. **Embedding**: Her chunk OpenAI API ile vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r
5. **Depolama**: VektÃ¶rler Pinecone cloud'da saklanÄ±r
6. **Sorgulama**: KullanÄ±cÄ± soru sorduÄŸunda:
   - Soru vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r
   - Pinecone'da benzer chunk'lar bulunur
   - Bulunan chunk'lar GPT'ye context olarak verilir
   - Model context'e gÃ¶re cevap Ã¼retir

## ğŸ”§ Sorun Giderme

### "API keys bulunamadÄ±" hatasÄ±
- `.env` dosyasÄ±nÄ±n proje klasÃ¶rÃ¼nde olduÄŸundan emin olun
- API key'lerin doÄŸru girildiÄŸini kontrol edin

### "Pinecone baÄŸlantÄ± hatasÄ±"
- Pinecone environment bilgisinin doÄŸru olduÄŸundan emin olun
- Ä°nternet baÄŸlantÄ±nÄ±zÄ± kontrol edin
- Pinecone hesabÄ±nÄ±zÄ±n aktif olduÄŸundan emin olun

### "DokÃ¼man iÅŸlenemedi" hatasÄ±
- Dosya formatÄ±nÄ±n desteklendiÄŸinden emin olun (PDF, TXT, DOCX)
- DosyanÄ±n bozuk olmadÄ±ÄŸÄ±nÄ± kontrol edin
- PDF'ler iÃ§in: DosyanÄ±n ÅŸifreli olmadÄ±ÄŸÄ±ndan emin olun

### "Vector dimension mismatch" hatasÄ±

**Sorun:** Mevcut Pinecone index'iniz farklÄ± bir dimension'da oluÅŸturulmuÅŸ.

**Ã‡Ã¶zÃ¼m 1 (Ã–nerilen):** `.env` dosyasÄ±nda index adÄ±nÄ± deÄŸiÅŸtirin:
```env
PINECONE_INDEX_NAME=rag-documents-v2
```
Yeni index otomatik oluÅŸturulacak. Eski verileriniz kaybolmayacak (eski index'te kalacak).

**Ã‡Ã¶zÃ¼m 2:** Pinecone dashboard'dan ([https://app.pinecone.io/](https://app.pinecone.io/)) eski index'i silin ve uygulamayÄ± yeniden baÅŸlatÄ±n.

**DoÄŸrulama:** Terminalde ÅŸu komutu Ã§alÄ±ÅŸtÄ±rÄ±n:
```powershell
python -c "import os; from dotenv import load_dotenv; load_dotenv(); print('Index Name:', os.getenv('PINECONE_INDEX_NAME'))"
```

### "gpt-5" model hatasÄ±

EÄŸer GPT-5'e eriÅŸiminiz yoksa, `config.py` dosyasÄ±nda:
```python
CHAT_MODEL = "gpt-4o"  # TÃ¼m hesaplarda Ã§alÄ±ÅŸÄ±r
```

## ğŸ“Š Maliyet Bilgileri

### Premium YapÄ±landÄ±rma (VarsayÄ±lan):
- **Embedding**: text-embedding-3-large - $0.13 / 1M tokens
- **Chat**: gpt-4o - Input: $5 / 1M tokens, Output: $15 / 1M tokens

### Ekonomik YapÄ±landÄ±rma:
```python
# config.py
EMBEDDING_MODEL = "text-embedding-3-small"  # $0.02 / 1M tokens
EMBEDDING_DIMENSION = 1536
CHAT_MODEL = "gpt-4o-mini"  # Input: $0.15, Output: $0.60 / 1M tokens
CHUNK_SIZE = 800
TOP_K = 5
```

## ğŸ’¡ Ä°puÃ§larÄ±

### Daha Ä°yi SonuÃ§lar Ä°Ã§in:
1. **Spesifik Sorular Sorun**: "X hakkÄ±nda ne sÃ¶yleniyor?" yerine "X'in Y Ã¼zerindeki etkisi nedir?"
2. **Context Verin**: Sorunuza context ekleyin
3. **Chunk SayÄ±sÄ±nÄ± AyarlayÄ±n**: `config.py`'da `TOP_K` deÄŸerini artÄ±rÄ±n (daha fazla context)
4. **Similarity Threshold'u AyarlayÄ±n**: Daha az ama daha ilgili sonuÃ§lar iÃ§in artÄ±rÄ±n (Ã¶r: 0.5)

### GPT-5 KullanÄ±mÄ±:

GPT-5 modellerini kullanmak isterseniz `config.py` dosyasÄ±nda:
```python
CHAT_MODEL = "gpt-5"  # veya "gpt-5-mini"
```

**Not:** GPT-5 modelleri temperature parametresini desteklemez (varsayÄ±lan 1 kullanÄ±r).

## ğŸ“ Notlar

- Ä°lk Ã§alÄ±ÅŸtÄ±rmada Pinecone index'i otomatik olarak oluÅŸturulur
- Her dokÃ¼man iÅŸleme ve sorgulama OpenAI API kullandÄ±ÄŸÄ± iÃ§in Ã¼crete tabidir
- Pinecone Ã¼cretsiz planÄ± 100.000 vektÃ¶re kadar destekler
- Maliyet Ã¶nceliÄŸinizse ekonomik yapÄ±landÄ±rmayÄ± kullanÄ±n

## ğŸ“„ Lisans

Bu proje eÄŸitim amaÃ§lÄ± oluÅŸturulmuÅŸtur.

## ğŸ¤ KatkÄ±da Bulunma

Ã–nerileriniz ve katkÄ±larÄ±nÄ±z iÃ§in pull request aÃ§abilirsiniz!
